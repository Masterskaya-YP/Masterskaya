{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f8d361-1615-4da0-a6d6-59848e338ba9",
   "metadata": {},
   "source": [
    "# –ê–±—Å—Ç—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd3608-5e6c-42f7-bada-463d68d7b1de",
   "metadata": {},
   "source": [
    "### –ö–æ–Ω—Ç–µ–∫—Å—Ç\n",
    "\n",
    "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ–≤–µ—Å—Ç–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –ø–æ–ª—É—á–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –º–µ—Ç–æ–¥–∞–º–∏ –∞–±—Å—Ç—Ä–∞–∫—Ç–∏–≤–Ω–æ–π —Å—É–º–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏.\n",
    "\n",
    "–ê–±—Å—Ç—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è ‚Äì —ç—Ç–æ –º–µ—Ç–æ–¥ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ—Ñ–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤–æ–µ –∫—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–æ–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.\n",
    "\n",
    "### –ß—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å?\n",
    "\n",
    "–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑—ã–Ω–µ –º–µ—Ç–æ–¥—ã –∞–±—Å—Ç—Ä–∞–∫—Ç–∏–≤–Ω–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:\n",
    "\n",
    "- T5 (Text-to-Text Transfer Transformer) - https://github.com/google-research/text-to-text-transfer-transformer\n",
    "- BART https://huggingface.co/docs/transformers/model_doc/bart\n",
    "\n",
    "### –†–µ–∑—É–ª—å—Ç–∞—Ç:\n",
    "\n",
    "- –∫–æ–¥ .py, .ipynb\n",
    "- –≤—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b04db-8322-46ba-93ae-8a71dfe5cf99",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏ –±–ª–æ–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1651a6dc-6325-4137-8b5b-ea08942fca58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (6.30.2)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from sentence-transformers) (4.50.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from sentence-transformers) (2.6.0+cpu)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from sentence-transformers) (4.12.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.20.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\agsav\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "!pip install sentencepiece --quiet\n",
    "!pip install protobuf --quiet\n",
    "!pip install --upgrade protobuf\n",
    "from transformers import (\n",
    "    MT5ForConditionalGeneration, \n",
    "    T5Tokenizer, \n",
    "    MBartForConditionalGeneration, \n",
    "    MBart50TokenizerFast,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM, \n",
    "    AutoModelForCausalLM)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# –î–ª—è –º–µ—Ç—Ä–∏–∫\n",
    "!pip install sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b7a450-8935-457f-b426-283b12448a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ csv –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ –∏–∑ –ø–∞—Ä—Å–∏–Ω–≥–∞ json –∏ —É–¥–∞–ª–µ–Ω–µ–∏–µ —Å—Ç—Ä–æ–∫, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —Å—Ç–æ–ª–±–µ—Ü text –ø—É—Å—Ç–æ–π\n",
    "\n",
    "def load_df(file, index=None):\n",
    "    pth1 = os.path.join('data', 'example', file)\n",
    "    pth2 = file\n",
    "\n",
    "    if os.path.exists(pth1):\n",
    "        df = pd.read_csv(pth1, na_values=np.nan)\n",
    "    elif os.path.exists(pth2):\n",
    "        df = pd.read_csv(pth2, na_values=np.nan)\n",
    "    else:\n",
    "        print('–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫')\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        df = df.dropna(subset=['text'])\n",
    "    except:\n",
    "        print('–°—Ç–æ–ª–±–µ—Ü \"text\" –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6bfe26c-3230-4a20-b048-e86089b39889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–∑–æ–±—å–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ —á–∞—Å—Ç–∏ (—á–∞–Ω–∫–∏) –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–ª–æ–≤\n",
    "\n",
    "def split_on_chunks(df, max_words_per_chunk=500):\n",
    "    current_words = 0\n",
    "    current_chunk = []\n",
    "    chunks = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ —Ç–µ–∫—É—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏\n",
    "        words_in_message = len(row['text'].split())\n",
    "        \n",
    "        # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç, —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–µ–π\n",
    "        if words_in_message > max_words_per_chunk:\n",
    "            # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–µ–π\n",
    "            words = row['text'].split()\n",
    "            while len(words) > max_words_per_chunk:\n",
    "                part = ' '.join(words[:max_words_per_chunk])\n",
    "                chunks.append([part])  # –î–æ–±–∞–≤–ª—è–µ–º —ç—Ç—É —á–∞—Å—Ç—å –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π —á–∞–Ω–∫\n",
    "                words = words[max_words_per_chunk:]\n",
    "            # –û—Å—Ç–∞–≤—à—É—é—Å—è —á–∞—Å—Ç—å –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫\n",
    "            if words:\n",
    "                chunks.append([' '.join(words)])\n",
    "        elif current_words + words_in_message > max_words_per_chunk:\n",
    "            # –ï—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø—Ä–µ–≤—ã—Å–∏—Ç –ª–∏–º–∏—Ç, –¥–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫\n",
    "            chunks.append(current_chunk)\n",
    "            # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π —á–∞–Ω–∫ —Å —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è\n",
    "            current_chunk = [row['text']]\n",
    "            current_words = words_in_message\n",
    "        else:\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∫ —Ç–µ–∫—É—â–µ–º—É —á–∞–Ω–∫—É\n",
    "            current_chunk.append(row['text'])\n",
    "            current_words += words_in_message\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61fbfd1f-baf8-4209-8c48-c0dd7cc34f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–±—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n",
    "def summarize_chunk(chunk, tokenizer, model, prefix=''):\n",
    "    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —á–∞—Å—Ç–∏ –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç\n",
    "    text = ' '.join(chunk)\n",
    "    \n",
    "    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è –º–æ–¥–µ–ª–∏\n",
    "    input_text = prefix + text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"longest\")\n",
    "    \n",
    "    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=150, min_length=50, length_penalty=2, early_stopping=True)\n",
    "    \n",
    "    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    summary = summary.replace(\"summarize: \", \"\") # —É–±–∏—Ä–∞–µ–º \"summarize: \" –¥–ª—è BART\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "449c7bdc-d8bc-4109-87fa-aaf74eaa64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—Ç–¥–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è ruGPT3\n",
    "def summarize_with_rugpt3(text, tokenizer, model, max_length=150):\n",
    "    prompt = f\"–¢–µ–∫—Å—Ç: {text.strip()}\\n–ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=input_ids.shape[1] + max_length,\n",
    "        do_sample=True,\n",
    "        temperature=0.8,\n",
    "        top_p=0.95,\n",
    "        top_k=50,\n",
    "        num_beams=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    generated = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    summary_start = generated.find(\"–ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:\")\n",
    "    return generated[summary_start + len(\"–ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:\"):].strip() if summary_start != -1 else generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "262a58d7-4982-4d76-9af6-86f064c99810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞\n",
    "def calculate_similarity(original_text, summary_text):\n",
    "    # –º–æ–¥–µ–ª—å SentenceTransformer, –∏ –º–µ—Ç–æ–¥ encode –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ —á–∏—Å–ª–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ\n",
    "    model_st = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    emb_src = model_st.encode(original_text, convert_to_tensor=True) \n",
    "    emb_sum = model_st.encode(summary_text, convert_to_tensor=True)\n",
    "    \n",
    "    # Cosine similarity\n",
    "    cos_sim = util.pytorch_cos_sim(emb_src, emb_sum)\n",
    "    cos_sim_score = cos_sim.item()\n",
    "    \n",
    "    return cos_sim_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1098eb-88b6-4198-a7c0-9e4112f0d4c9",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "685fd85c-777d-4e7c-b6e0-dfede3ddff55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>chat_name</th>\n",
       "      <th>chat_id</th>\n",
       "      <th>sender_id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-03T11:28:38</td>\n",
       "      <td>üí¨ Data Practicum Chat</td>\n",
       "      <td>1379846874</td>\n",
       "      <td>user312724902</td>\n",
       "      <td>Olga Varavina</td>\n",
       "      <td>–í—Å–µ–º –±–æ–ª—å—à–æ–π –ø—Ä–∏–≤–µ—Ç! –ü—Ä–∏–≥–ª–∞—à–∞—é –Ω–∞ —Å–≤–æ–π —É—é—Ç–Ω—ã–π ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-03T11:52:20</td>\n",
       "      <td>üí¨ Data Practicum Chat</td>\n",
       "      <td>1379846874</td>\n",
       "      <td>user1349934990</td>\n",
       "      <td>–ò–ª—å—è</td>\n",
       "      <td>–ê —É —Ç–µ–±—è –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç —Å–≤–æ–π –∫–∞–Ω–∞–ª –ø—Ä–æ –∞–Ω–∞–ª–∏—Ç–∏–∫—É?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-03T11:52:37</td>\n",
       "      <td>üí¨ Data Practicum Chat</td>\n",
       "      <td>1379846874</td>\n",
       "      <td>user1349934990</td>\n",
       "      <td>–ò–ª—å—è</td>\n",
       "      <td>–ë—É–¥–µ—à—å —Ç—É–¥–∞ –≥–æ–ª–æ—Å–æ–≤—É—Ö–∏ –ø—è—Ç–∏–º–∏–Ω—É—Ç–Ω—ã–µ –ø–æ—Å—Ç–∏—Ç—å</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-02-03T11:55:09</td>\n",
       "      <td>üí¨ Data Practicum Chat</td>\n",
       "      <td>1379846874</td>\n",
       "      <td>user60031833</td>\n",
       "      <td>Sergey</td>\n",
       "      <td>–ü–æ—Ç–æ–º—É —á—Ç–æ —Å–¥–µ–ª–∞–Ω—ã —Ç–∞–∫, –±—É–¥—Ç–æ —É—Å—Ç–∞—Ä–µ–ª–∏ —É–∂–µ –ª–µ—Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-02-03T11:56:57</td>\n",
       "      <td>üí¨ Data Practicum Chat</td>\n",
       "      <td>1379846874</td>\n",
       "      <td>user60031833</td>\n",
       "      <td>Sergey</td>\n",
       "      <td>–ü–æ–¥–∫–∞—Å—Ç?)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date              chat_name     chat_id       sender_id  \\\n",
       "2  2025-02-03T11:28:38  üí¨ Data Practicum Chat  1379846874   user312724902   \n",
       "3  2025-02-03T11:52:20  üí¨ Data Practicum Chat  1379846874  user1349934990   \n",
       "4  2025-02-03T11:52:37  üí¨ Data Practicum Chat  1379846874  user1349934990   \n",
       "5  2025-02-03T11:55:09  üí¨ Data Practicum Chat  1379846874    user60031833   \n",
       "6  2025-02-03T11:56:57  üí¨ Data Practicum Chat  1379846874    user60031833   \n",
       "\n",
       "        username                                               text  \n",
       "2  Olga Varavina  –í—Å–µ–º –±–æ–ª—å—à–æ–π –ø—Ä–∏–≤–µ—Ç! –ü—Ä–∏–≥–ª–∞—à–∞—é –Ω–∞ —Å–≤–æ–π —É—é—Ç–Ω—ã–π ...  \n",
       "3           –ò–ª—å—è     –ê —É —Ç–µ–±—è –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç —Å–≤–æ–π –∫–∞–Ω–∞–ª –ø—Ä–æ –∞–Ω–∞–ª–∏—Ç–∏–∫—É?  \n",
       "4           –ò–ª—å—è        –ë—É–¥–µ—à—å —Ç—É–¥–∞ –≥–æ–ª–æ—Å–æ–≤—É—Ö–∏ –ø—è—Ç–∏–º–∏–Ω—É—Ç–Ω—ã–µ –ø–æ—Å—Ç–∏—Ç—å  \n",
       "5         Sergey  –ü–æ—Ç–æ–º—É —á—Ç–æ —Å–¥–µ–ª–∞–Ω—ã —Ç–∞–∫, –±—É–¥—Ç–æ —É—Å—Ç–∞—Ä–µ–ª–∏ —É–∂–µ –ª–µ—Ç...  \n",
       "6         Sergey                                          –ü–æ–¥–∫–∞—Å—Ç?)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_df('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "205c82df-7d70-4250-bd00-83bc69a99475",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_on_chunks(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea28c34-ae38-44e3-a60a-297b6662ce29",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91ec6726-dda0-46cb-9107-c69f60f091fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_t5 = T5Tokenizer.from_pretrained(\"google/mt5-small\", legacy=False)\n",
    "model_t5 = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa0f53d9-92b2-4192-9cf1-1e14606c4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_bart = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50\", src_lang=\"ru_RU\", tgt_lang=\"ru_RU\")\n",
    "model_bart = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6009bd4b-6547-4a5e-8478-269d8084c9f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer_rut5 = AutoTokenizer.from_pretrained(\"cointegrated/rut5-small\")\n",
    "model_rut5 = AutoModelForSeq2SeqLM.from_pretrained(\"cointegrated/rut5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01179833-9bed-4f47-90b6-d25c1d05d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_gpt3 = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")\n",
    "model_gpt3 = AutoModelForCausalLM.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1b95a94-63b2-4802-a831-44169ec8edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_rut5_bsg = AutoTokenizer.from_pretrained(\"IlyaGusev/rut5_base_sum_gazeta\")\n",
    "model_rut5_bsg = AutoModelForSeq2SeqLM.from_pretrained(\"IlyaGusev/rut5_base_sum_gazeta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f85765-a667-421f-9fcd-92886c0cfbb0",
   "metadata": {},
   "source": [
    "### –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a6944d-ab8c-42bc-ab95-d9660f7d6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—é —Å—Ä–µ–∑ —á–∞–Ω–∫–æ–≤ chunks[1:3], –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–æ –≤—Å–µ–º, —É–±–µ—Ä–∏ [1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "404d3fef-c0a8-4099-a014-edd032063021",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_summaries_bart = [summarize_chunk(chunk, tokenizer_bart, model_bart) for chunk in chunks[1:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea0026a1-1d8d-472f-9bce-b5f420c7e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_summaries_t5 = [summarize_chunk(chunk, tokenizer_t5, model_t5, prefix=\"summarize: \") for chunk in chunks[1:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f0c6f17-8003-4b3a-9cb4-0e3fa7e163ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_summaries_rut5 = [summarize_chunk(chunk, tokenizer_rut5, model_rut5, prefix=\"summarize: \") for chunk in chunks[1:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d40015de-9d8b-4672-93a5-23ac806c24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_summaries_rut5_bsg = [summarize_chunk(chunk, tokenizer_rut5_bsg, model_rut5_bsg, prefix=\"summarize: \") for chunk in chunks[1:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "190e859a-e136-4576-be97-966fd75083dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_summaries_gpt3 = [summarize_with_rugpt3(' '.join(chunk), tokenizer_gpt3, model_gpt3) for chunk in chunks[1:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc8972e1-7a92-4b42-ac08-b6191a5125f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<extra_id_0> –∏ —Ç.–¥.))))))))))))))))))))))))))))))))))))))))))))))))))) ().) )) )) )) )) )) )) )) ))) ))) )) ))) ))) ))) ))) ))))))))))))))))))))))))))))))))))))))',\n",
       " '<extra_id_0> –Ω–µ –∑–Ω–∞—é. –ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ, –∞ –Ω–∞–ø–∏—Å–∞—Ç—å –≤ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ. –ò–Ω—Å–∞–π—Ç—ã. –ú–æ–∂–Ω–æ –≤ –ª—é–±–æ–º —Ñ–æ—Ä–º–∞—Ç–µ. –ú–æ–∂–µ—Ç. –º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ –≤ –ª—é–±–æ–º —Ñ–æ—Ä–º–∞—Ç–µ. –ú–æ–∂–µ—Ç. –º–æ–∂–Ω–æ.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_summaries_t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e50be3c-a7f0-4a17-8ec6-05fc6ac94ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ—É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –±–µ—Ç–∞-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ü—Ä–æ–¥—É–∫—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ BI-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞ *–¥–ª—è –≤—ã–ø—É—Å–∫–Ω–∏–∫–æ–≤ –∫—É—Ä—Å–æ–≤ \"–ê–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö\", \"–ê–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π\" –∏ \"–ê–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö Bootcamp\" –í—Å–µ–º –ø—Ä–∏–≤–µ—Ç! –ù–∞ —Å–≤—è–∑–∏ –∫–æ–º–∞–Ω–¥–∞ –∫—É—Ä—Å–æ–≤ –ê–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö. –ú—ã –∞–∫—Ç–∏–≤–Ω–æ —Ä–∞–±–æ—Ç–∞–µ–º –Ω–∞–¥ –∫—É—Ä—Å–∞–º–∏ –ü—Ä–æ–¥—É–∫—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ BI-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞, –∏ —Å–µ–π—á–∞—Å –º—ã –≤ –ø–æ–∏—Å–∫–µ –±–µ—Ç–∞-—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫–æ–≤ –Ω–æ–≤—ã—Ö –∫—É—Ä—Å–æ–≤. –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –Ω–∞–≤—ã–∫–∏ –≤ –∞–Ω–∞–ª–∏—Ç–∏–∫–µ –¥–∞–Ω–Ω—ã—Ö, –∏–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É –º—ã –ø—Ä–∏—à–ª–∏ –∫ –≤–∞–º ‚Äî –Ω–∞—à–∏–º –≤—ã–ø—É—Å–∫–Ω–∏–∫–∞–º #–±–µ—Ç–∞-—Ç–µ—Å—Ç ‚Äî —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –±–µ—Å–ø–ª–∞—Ç–Ω–æ –ø—Ä–æ–π—Ç–∏ –æ–±—É—á–µ–Ω–∏–µ —Å —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ–º –≤ –Ø–Ω–¥–µ–∫—Å –ü—Ä–∞–∫—Ç–∏–∫—É–º–µ. –ì–ª–∞–≤–Ω–∞—è',\n",
       " '—è –Ω–∞–ø–∏—Å–∞–ª –≤ —Å–∞–ø–ø–æ—Ä—Ç =D + –í—Å–µ —É–∂–µ –æ–±–æ–∑–Ω–∞—á–∏–ª–∏, —á—Ç–æ —Å—Å—ã–ª–∫–∞ –Ω–∞ Nda –Ω–µ–∞–∫—Ç–∏–≤–Ω–∞? –©–∞—Å –ø—Ä–æ–≤–µ—Ä—é –∏ –Ω–∞–ø–∏—à—É –ù–µ –º–æ–≥—É –ø–æ–¥–ø–∏—Å–∞—Ç—å NDA \"–°—Å—ã–ª–∫–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω–∞. –ó–∞–ø—Ä–æ—Å–∏—Ç–µ –Ω–æ–≤—É—é —Å—Å—ã–ª–∫—É\"... –î–∞–≤–∞–π —É–∂–µ –ø–µ—Ä–≤—ã–µ –ø–æ–¥–∫–∞—Å—Ç—ã, –∞ —Ç–æ –Ω–∞—á–Ω—É—Ç—Å—è –æ—Ç–ø–∏—Å–∫–∏ –û—Ç–ø–∏—Å–∫–∏ –Ω–∞—á–Ω—É—Ç—Å—è, –∫–æ–≥–¥–∞ –ø–æ–π–¥—É—Ç –º–æ–∏ –ø–æ–¥–∫–∞—Å—Ç—ã –ü–æ–¥–ø–∏—Å–∞–ª—Å—è –í–æ–æ–±—â–µ, –±—ã–ª–æ –±—ã –Ω–µ–ø–ª–æ—Ö–æ, –µ—Å–ª–∏ –≤—Å–µ —É—á–∞—Å—Ç–Ω–∏–∫–∏ –∑–∞–ø–∏—Å—ã–≤–∞–ª–∏ —Ç—É–¥–∞ –∫–∞–∫–∏–µ- —Ç–æ –∫–µ–π—Å—ã —Ä–∞–±–æ—á–∏–µ. –ò–Ω—Å–∞–π—Ç—ã. –ú–æ–∂–Ω–æ –≤ –ª—é–±–æ–º —Ñ–æ—Ä–º–∞—Ç–µ. –ù–∞–ø–∏—Å–∞–ª –≤ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ, –Ω–æ —Ç–∞–º –ø–æ –ø—Ä–µ–∂–Ω–µ–º—É —Ç–∏—à–∏–Ω–∞:) –•–æ—á–µ—à—å —á—Ç–æ–±—ã –≤—Å–µ –≥–æ–¥–æ—Å–æ–≤—É—Ö–∏ –ø–∏—Å–∞–ª–∏? –û—Ç–ø—Ä–∞–≤–∏–ª –∑–∞—è–≤–∫—É, –Ω–æ –±–µ–∑ NDA']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_summaries_bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f480b39-0d40-4ed6-9bfe-05e7e77b1af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–ß—Ç–æ –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å —Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫—É, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è, –∏–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É –º—ã –ø—Ä–∏—à–ª–∏ –∫ —Ç–µ–±–µ –≤ –±–µ—Ç–∞-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å —É—á—ë–±—ã, –∏–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É –º—ã –≤ –ø–æ–∏—Å–∫–µ –±–µ—Ç–∞-—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫–æ–≤, –∏–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É –º—ã –≤ –ø–æ–∏—Å–∫–µ –±–µ—Ç–∞-—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫–æ–≤, –∏–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É –º—ã –≤ –ø–æ–∏—Å–∫–µ –±–µ—Ç–∞-—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫–æ–≤, –∏–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É –º—ã –≤ –ø–æ–∏—Å–∫–µ –±–µ—Ç–∞-—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫–æ–≤, –∏–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É –º—ã —Å–º–æ–∂–µ–º –≤—ã–¥–∞—Ç—å –¥–∏–ø–ª–æ–º—ã –æ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–∏ –∫—É—Ä—Å–∞, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å —É—á—ë–±—ã',\n",
       " '–ß—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø–ª–æ—Ö–æ, –µ—Å–ª–∏ –≤—Å–µ —É—á–∞—Å—Ç–Ω–∏–∫–∏ –∑–∞–ø–∏—Å—ã–≤–∞–ª–∏ —Ç—É–¥–∞ –∫–∞–∫–∏–µ-—Ç–æ –∫–µ–π—Å—ã —Ä–∞–±–æ—á–∏–µ, –ò–Ω—Å–∞–π—Ç—ã, –∞ —Ç–æ–∂–µ –æ—Ç–ø—Ä–∞–≤–∏–ª–∞ –∑–∞—è–≤–∫—É –±–µ–∑ NDA, –∫–∞–∫ —Ç–æ–ª—å–∫–æ –æ—Å—Ç–∞–≤–∏–ª–∞ –∑–∞—è–≤–∫—É –±–µ–∑ NDA, –∫–∞–∫ —Ç–æ–ª—å–∫–æ –æ—Å—Ç–∞–≤–∏–ª–∞ –∑–∞—è–≤–∫—É –±–µ–∑ NDA, –∫–∞–∫ —Ç–æ–ª—å–∫–æ –æ—Å—Ç–∞–≤–∏–ª–∞ –∑–∞—è–≤–∫—É –±–µ–∑ NDA, –∫–∞–∫ —Ç–æ–ª—å–∫–æ –æ—Å—Ç–∞–≤–∏–ª–∞ –∑–∞—è–≤–∫—É –±–µ–∑ —Å—Å—ã–ª–∫–∏, –Ω–æ –Ω–µ –º–æ–≥—É –ø–æ–¥–ø–∏—Å–∞—Ç—å –æ—Ç–ø—Ä–∞–≤–∏–ª –∑–∞—è–≤–∫—É, –Ω–æ –Ω–µ –º–æ–≥—É –ø–æ–¥–ø–∏—Å–∞—Ç—å, –∫–∞–∫ —Ç–æ–ª—å–∫–æ –º–æ–∂–Ω–æ –ø–æ–¥–ø–∏—Å–∞—Ç—å, –∫–∞–∫ —Ç–æ–ª—å–∫–æ –º–æ–∂–Ω–æ –ø–æ–¥–ø–∏—Å–∞—Ç—å, –∫–∞–∫ —Ç–æ–ª—å–∫–æ –º–æ–∂–Ω–æ –ø–æ–¥–ø–∏—Å–∞—Ç—å, –∫–∞–∫ —Ç–æ–ª—å–∫–æ –º–æ–∂–Ω–æ –ø–æ–¥–ø–∏—Å–∞—Ç—å, –∫–∞–∫ —Ç–æ–ª—å–∫–æ –º–æ–∂–Ω–æ –ø–æ–¥–ø–∏—Å–∞—Ç—å,']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_summaries_rut5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a52f0be6-4ef4-4424-893f-0fd3a5794df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–í—ã–ø—É—Å–∫–Ω–∏–∫–∏ –∫—É—Ä—Å–æ–≤ –ü—Ä–æ–¥—É–∫—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ BI-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ–ª—É—á–∞—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –±–µ—Å–ø–ª–∞—Ç–Ω–æ –ø—Ä–æ–π—Ç–∏ –±–µ—Ç–∞-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ü—Ä–æ–¥—É–∫—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ BI-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ–º –≤ –Ø–Ω–¥–µ–∫—Å –ü—Ä–∞–∫—Ç–∏–∫—É–º–µ. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±—É–¥–µ—Ç –ø—Ä–æ—Ö–æ–¥–∏—Ç—å —Å —Å–µ—Ä–µ–¥–∏–Ω—ã —Ñ–µ–≤—Ä–∞–ª—è 2025 –ø–æ –Ω–∞—á–∞–ª–æ –∏—é–Ω—è 2025.',\n",
       " '–ï—Å–ª–∏ –≤—Å–µ —É—á–∞—Å—Ç–Ω–∏–∫–∏ –∫—É—Ä—Å–∞ LLM –±—É–¥—É—Ç –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å —Å–≤–æ–∏ –≥–æ–¥–æ—Å–æ–≤—É—Ö–∏, —Ç–æ –Ω–∞—á–Ω—É—Ç—Å—è –æ—Ç–ø–∏—Å–∫–∏, –∫–æ–≥–¥–∞ –ø–æ–π–¥—É—Ç –º–æ–∏ –ø–æ–¥–∫–∞—Å—Ç—ã, –∞ —Ç–æ –Ω–∞—á–Ω—É—Ç—Å—è –æ—Ç–ø–∏—Å–∫–∏, –∫–æ–≥–¥–∞ –ø–æ–π–¥—É—Ç –º–æ–∏ –ø–æ–¥–∫–∞—Å—Ç—ã.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_summaries_rut5_bsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07d22d8b-f94c-457d-b4b8-d85dc1e9bbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"–ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –ø—Ä–æ–¥—É–∫—Ç–∞\" - —ç—Ç–æ –Ω–∞–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π, –∫–æ–¥–æ–≤ –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–∏–∑–Ω–µ—Å –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–∏–∑–Ω–µ—Å –ø—Ä–æ—Ü–µ—Å—Å–æ–≤. –ü—Ä–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–¥—É–∫—Ç–æ–≤, —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ –æ–±—ã—á–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –Ω–∞–±–æ—Ä –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤. –ö–∞–∂–¥—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –≤ —Å–≤–æ—é –æ—á–µ—Ä–µ–¥—å, —è–≤–ª—è–µ—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –≤—Å–µ —ç—Ç–∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–≤—è–∑–∞–Ω—ã –º–µ–∂–¥—É —Å–æ–±–æ–π.\\n–î–∞–Ω–Ω—ã–π –∫–æ–¥ –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —à–∞–≥–æ–≤, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞. –ö–æ–¥ - —á–∞—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –ø–æ—ç—Ç–æ–º—É –æ–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω —Ç–∞–∫–∏–º, –∫–∞–∫–∏–º –æ–Ω –æ–ø–∏—Å–∞–Ω. –ê–ª–≥–æ—Ä–∏—Ç–º - –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö - –∏–Ω—Å—Ç—Ä—É–∫—Ç–∏—Ä—É—é—â–∏—Ö, —É–ø—Ä–∞–≤–ª—è—é—â–∏—Ö –∏ —É–ø—Ä–∞–≤–ª—è—é—â–∏—Ö, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è. –í –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤, –∞–ª–≥–æ—Ä–∏—Ç–º –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –≤ –¥–≤—É—Ö –≤–∏–¥–∞—Ö: –∞–ª–≥–æ—Ä–∏—Ç–º –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è. –ö–∞–∂–¥–æ–µ –∏–∑ —ç—Ç–∏—Ö –ø–æ–Ω—è—Ç–∏–π –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Å–ø–æ—Å–æ–±',\n",
       " '–ú—ã –≤—Å–µ —É—á–∏–ª–∏—Å—å, –º—ã –≤—Å–µ —Ä–∞–±–æ—Ç–∞–µ–º.\\n–í—Å–µ –ª–∏ –∑–Ω–∞—é—Ç, —á–µ–≥–æ –æ–Ω–∏ —Ö–æ—Ç—è—Ç?\\n–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—Ç—Ä–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è. –í—ã—è–≤–ª–µ–Ω–∏–µ —Å–∏–ª—å–Ω—ã—Ö –∏ —Å–ª–∞–±—ã—Ö —Å—Ç–æ—Ä–æ–Ω. –ö–∞–∫ —Å –ø–æ–º–æ—â—å—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–Ω—è—Ç—å —Å–≤–æ—é –∑–∞–¥–∞—á—É –Ω–∞ —Ä—ã–Ω–∫–µ —Ç—Ä—É–¥–∞? –ö–∞–∫ –ø–æ–≤—ã—Å–∏—Ç—å —Å–≤–æ—é –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—å? –ö–∞–∫–æ–π –∏–∑ –Ω–∞–≤—ã–∫–æ–≤ —è–≤–ª—è–µ—Ç—Å—è —Å–∞–º—ã–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º –∏ –≤—ã–≥–æ–¥–Ω—ã–º –¥–ª—è —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—è? –ö–∞–∫–∏–µ –Ω–∞–≤—ã–∫–∏ –º–æ–≥—É—Ç –ø–æ–º–µ—à–∞—Ç—å –Ω–∞–π—Ç–∏ —Ö–æ—Ä–æ—à—É—é —Ä–∞–±–æ—Ç—É? \\n\\n1) –ö–∞–∫ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å–≤–æ–∏ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã? \\n2) –ö–∞–∫–∏–µ –æ—à–∏–±–∫–∏ —Å–æ–≤–µ—Ä—à–∞—é—Ç –ø—Ä–∏ –ø–æ–¥–±–æ—Ä–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤? –ß—Ç–æ –¥–µ–ª–∞–µ—Ç —á–µ–ª–æ–≤–µ–∫, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –∑–Ω–∞–µ—Ç —Å–≤–æ–∏—Ö —Å–∏–ª—å–Ω—ã—Ö —Å—Ç–æ—Ä–æ–Ω? –ì–¥–µ –æ–Ω –∏—Ö –∏—â–µ—Ç? –ö—Ç–æ –º–æ–∂–µ—Ç –∏—Ö —Ä–∞—Å–∫—Ä—ã—Ç—å? –ò —á—Ç–æ –¥–µ–ª–∞—Ç—å,–µ—Å–ª–∏ –æ–Ω –≤–∏–¥–∏—Ç –∏—Ö –≤ –¥—Ä—É–≥–æ–º —á–µ–ª–æ–≤–µ–∫–µ? (–æ–± —ç—Ç–æ–º —è –ø–∏—Å–∞–ª –≤ —Å—Ç–∞—Ç—å–µ \"–ü–æ—á–µ–º—É —è –Ω–µ –ª—é–±–ª—é —Ä–∞–±–æ—Ç–∞—Ç—å\" httpss://vk.com/w']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_summaries_gpt3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57a6e4e-8807-457a-85cf-9ee29b65dcc4",
   "metadata": {},
   "source": [
    "### –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55edab95-88d9-4762-9b19-a82d8d6c8ff0",
   "metadata": {},
   "source": [
    "Cosine Similarity (–∫–æ—Å–∏–Ω—É—Å–Ω–∞—è –º–µ—Ä–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9d9ad36-19bf-491f-bd45-44d952895f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Chunk\": [],\n",
    "    \"BART\": [],\n",
    "    \"T5\": [],\n",
    "    \"rut5\": [],\n",
    "    \"rut5_bsg\": [], \n",
    "    \"rugpt3\": []\n",
    "}\n",
    "\n",
    "for i in range(1, 3):\n",
    "    original_text = ' '.join(chunks[i-1])\n",
    "    \n",
    "    summary_bart = chunk_summaries_bart[i-1]\n",
    "    cos_sim_bart = calculate_similarity(original_text, summary_bart)\n",
    "    \n",
    "    summary_t5 = chunk_summaries_t5[i-1]\n",
    "    cos_sim_t5 = calculate_similarity(original_text, summary_t5)\n",
    "    \n",
    "    summary_rut5 = chunk_summaries_rut5[i-1]\n",
    "    cos_sim_rut5 = calculate_similarity(original_text, summary_rut5)\n",
    "    \n",
    "    summary_rut5_bsg = chunk_summaries_rut5_bsg[i-1]\n",
    "    cos_sim_rut5_bsg = calculate_similarity(original_text, summary_rut5_bsg)\n",
    "    \n",
    "    summary_gpt3 = chunk_summaries_gpt3[i-1]\n",
    "    cos_sim_gpt3 = calculate_similarity(original_text, summary_gpt3)\n",
    "    \n",
    "    results[\"Chunk\"].append(f\"Chunk {i}\")\n",
    "    results[\"BART\"].append(cos_sim_bart)\n",
    "    results[\"T5\"].append(cos_sim_t5)\n",
    "    results[\"rut5\"].append(cos_sim_rut5)\n",
    "    results[\"rut5_bsg\"].append(cos_sim_rut5_bsg)\n",
    "    results[\"rugpt3\"].append(cos_sim_gpt3)\n",
    "\n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25bb9350-fb65-42e2-a2cb-b829258ee3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunk</th>\n",
       "      <th>BART</th>\n",
       "      <th>T5</th>\n",
       "      <th>rut5</th>\n",
       "      <th>rut5_bsg</th>\n",
       "      <th>rugpt3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunk 1</td>\n",
       "      <td>0.436778</td>\n",
       "      <td>0.225437</td>\n",
       "      <td>0.204232</td>\n",
       "      <td>0.279810</td>\n",
       "      <td>0.266572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chunk 2</td>\n",
       "      <td>0.251637</td>\n",
       "      <td>0.157351</td>\n",
       "      <td>0.178092</td>\n",
       "      <td>0.385551</td>\n",
       "      <td>0.498198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Chunk      BART        T5      rut5  rut5_bsg    rugpt3\n",
       "0  Chunk 1  0.436778  0.225437  0.204232  0.279810  0.266572\n",
       "1  Chunk 2  0.251637  0.157351  0.178092  0.385551  0.498198"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915d25d-f414-47d1-9bc3-20ea73a90c4b",
   "metadata": {},
   "source": [
    "### –í—ã–≤–æ–¥\n",
    " - –î–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Å—Ä–µ–∑ –∏–∑ –¥–≤—É—Ö –∫—É—Å–∫–æ–≤(chunks).\n",
    " - –ü–æ–ø—Ä–æ–±–æ–≤–∞–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Å—É–º–∞—Ä–∏–∑–∞—Ü–∏–∏:\n",
    "     - mT5 - –º–Ω–æ–≥–æ—è–∑—ã–∫–æ–≤—É—é –≤–µ—Ä—Å–∏—é T5, –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—É—é –Ω–∞ –º–Ω–æ–≥–æ—è–∑—ã–∫–æ–≤–æ–º –∫–æ—Ä–ø—É—Å–µ Common Crawl (mC4), –æ—Ö–≤–∞—Ç—ã–≤–∞—é—â–µ–º 101 —è–∑—ã–∫;\n",
    "     - mBART-50\t–º–Ω–æ–≥–æ—è–∑—ã–∫–æ–≤—É—é –≤–µ—Ä—Å–∏—é BART, –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—É—é –Ω–∞ 50 —è–∑—ã–∫–∞—Ö;\n",
    "     - rut5 - —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–∏ google/mt5-small;\n",
    "     - rugpt3large_based_on_gpt2 - –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ GPT-2, –Ω–æ –æ–±—É—á–µ–Ω–∏–µ —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–ª–æ—Å—å –Ω–∞ –¥–∞–Ω–Ω—ã—Ö —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞.\n",
    " - mT5 –Ω–∞ –≤—ã—Ö–æ–∂–¥–µ –Ω–µ –¥–∞–µ—Ç –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã, —Ç–∞–∫–∏–µ –∫–∞–∫, –Ω–∞–ø—Ä–∏–º–µ—Ä, 'extra_id_0', –Ω–µ —Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–∏–ª –ø–∞—Ä–∞–º–µ—Ç—Ä, –∫–æ—Ç–æ—Ä—ã–π –¥–æ–ª–∂–µ–Ω –∏—Ö —É–±–∏—Ä–∞—Ç—å skip_special_tokens=True.\n",
    " - mBART-50 –¥–∞–ª–∞ —Ö–æ—Ä–æ—à—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.\n",
    " - rut5 –¥–∞–ª–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –ª—É—á—à–µ —á–µ–º mT5. –ù–æ –µ—Å—Ç—å –º–Ω–æ–≥–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –ø–æ–≤—Ç–æ—Ä—ã —Å–ª–æ–≤ –≤ —Å—É–º–º–∞—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n",
    " - rugpt3large_based_on_gpt2 - –Ω–µ —Å–º–æ—Ç—Ä—è –Ω–∞ –º–æ–∏ –æ–∂–∏–¥–∞–Ω–∏—è, –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–æ —Å—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞–ª–∞ —Ç–µ–∫—Å—Ç –∏ –¥–æ–±–∞–≤–ª—è–ª–∞ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä, \"\\n\".\n",
    " - Cosine Similarity (–∫–æ—Å–∏–Ω—É—Å–Ω–∞—è –º–µ—Ä–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏) –ø–æ–∫–∞–∑–∞–ª–∞ –Ω–∏–∑–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è, –∞ —á–µ–º –Ω–∏–∂–µ –º–µ—Ç—Ä–∏–∫–∞ —Ç–µ–º —Ç–µ–∫—Å—Ç—ã –º–µ–Ω–µ–µ —Å—Ö–æ–∂–∏. –Ø –ø–æ–ª—É—á–∏–ª –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É –Ω–∞ rugpt3 ~0.45 –∏ mBART-50 ~0.44. –û—Å—Ç–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ–Ω—å—à–µ 0.4 –∏ –≥–æ–≤–æ—Ä—è—Ç –æ —Ç–æ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ —Ä–∞–∑–Ω—ã–º–∏.\n",
    " - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –Ω–µ–±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏, –Ω–æ –∏ –Ω–∞ –Ω–∏—Ö —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Ñ–∏—Å–Ω–æ–º –Ω–æ—É—Ç–±—É–∫–µ –ø—Ä–æ–∏—Ö–æ–¥–∏—Ç –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ.\n",
    " - –í–æ–∑–º–æ–∂–Ω–æ, —Å–ª–µ–¥—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –∑–∞–¥–∞—á —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ–Ω–∫–∏ —á–µ—Ä–µ–∑ API, –µ—Å–ª–∏ –Ω–µ—Ç —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–æ–ª–µ–µ –º–æ—â–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595376e2-dfe4-452e-8796-4f8d5dbea7be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
